{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (TextDataset, DataCollatorForLanguageModeling,GPT2Tokenizer,\n",
    "                          GPT2LMHeadModel,Trainer, TrainingArguments)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "wandb.init(mode=\"disabled\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>\\nI feel like I was born in the wrong body I f...</td>\n",
       "      <td>Hi. Do you have any opportunity to work with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>My friend is abusing her prescription medicine...</td>\n",
       "      <td>Your friend needs to admit they have a problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>\\nI have so many issues to address. I have a h...</td>\n",
       "      <td>Hello! You may have heard the saying that coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6556</th>\n",
       "      <td>\\nHow does a counselor decide when to end coun...</td>\n",
       "      <td>For a therapist, deciding to end counseling se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>\\nI love my girlfriend so much. I get an erect...</td>\n",
       "      <td>I'm sorry to hear of your problem.First step a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  \\\n",
       "6248  \\nI feel like I was born in the wrong body I f...   \n",
       "3438  My friend is abusing her prescription medicine...   \n",
       "6476  \\nI have so many issues to address. I have a h...   \n",
       "6556  \\nHow does a counselor decide when to end coun...   \n",
       "5862  \\nI love my girlfriend so much. I get an erect...   \n",
       "\n",
       "                                               Response  \n",
       "6248  Hi. Do you have any opportunity to work with a...  \n",
       "3438  Your friend needs to admit they have a problem...  \n",
       "6476  Hello! You may have heard the saying that coun...  \n",
       "6556  For a therapist, deciding to end counseling se...  \n",
       "5862  I'm sorry to hear of your problem.First step a...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('../data/sample_q_and_a/response_2.csv')\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7115 entries, 0 to 7114\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  7115 non-null   object\n",
      " 1   Response  7111 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 111.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/sample_q_and_a/train_response2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size = 1024):\n",
    "    dataset_train = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = file_path,\n",
    "        block_size = block_size,\n",
    "    )\n",
    "    return dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_collator(tokenizer, mlm = False):\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=mlm,\n",
    "    )\n",
    "    return data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_file_path, model_name, output_dir, overwrite_output_dir,\n",
    "          per_device_train_batch_size, num_train_epochs):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    # Load datasets\n",
    "    train_dataset = load_dataset(train_file_path, tokenizer)\n",
    "\n",
    "    # Load data collator\n",
    "    data_collator = load_data_collator(tokenizer)\n",
    "\n",
    "    # Save tokenizer\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    # Load or initialize model\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    # Save model\n",
    "    model.save_pretrained(output_dir)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=overwrite_output_dir,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=4,\n",
    "        logging_dir=\"../data/sample_q_and_a/logs\",\n",
    "        logging_steps=100,  # Log every 100 steps\n",
    "        save_steps=500,  # Save checkpoint every 500 steps\n",
    "        logging_first_step=True,\n",
    "        save_total_limit=2,\n",
    "        learning_rate=.0001,\n",
    "        fp16 = True\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "    hist = trainer.train()\n",
    "    trainer.save_model()\n",
    "    return trainer,hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"../data/sample_q_and_a/train_response2.csv\"\n",
    "model_name = 'distilgpt2'\n",
    "output_dir = '../data/sample_q_and_a/custom_model'\n",
    "overwrite_output_dir = True\n",
    "per_device_train_batch_size = 2\n",
    "num_train_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Tokenizer(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-5): 6 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2690' max='2690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2690/2690 1:54:50, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.498500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.914400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.801200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.743300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.624700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.565800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.560300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.461600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.393700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.384800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.292400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.284500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.197400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.123600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.058200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.997600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.003700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "hist=train(\n",
    "    train_file_path=train_file_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step: 2690\n",
      "Epoch: 9.99\n",
      "Train Runtime: 6893.7156\n",
      "Train Samples Per Second: 3.123\n",
      "Train Steps Per Second: 0.39\n",
      "Total FLOPS: 5620754401984512.0\n",
      "Train Loss: 2.352705027002384\n"
     ]
    }
   ],
   "source": [
    "print(\"Global Step:\", hist[1].global_step)\n",
    "print(\"Epoch:\", hist[1].metrics['epoch'])\n",
    "print(\"Train Runtime:\", hist[1].metrics['train_runtime'])\n",
    "print(\"Train Samples Per Second:\", hist[1].metrics['train_samples_per_second'])\n",
    "print(\"Train Steps Per Second:\", hist[1].metrics['train_steps_per_second'])\n",
    "print(\"Total FLOPS:\", hist[1].metrics['total_flos'])\n",
    "print(\"Train Loss:\", hist[1].metrics['train_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate answer using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "def generate_text(model_path, sequence, max_length):\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    tokenizer = load_tokenizer(model_path)\n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    return tokenizer.decode(final_outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q :  I self-harm, and I stop for awhile. Then when I see something sad or depressing, I automatically want to self-harm.\n",
      "\n",
      "A :  Self-harm has a way of becoming a go-to method of coping. When we get stuck using self-harm as a way to deal and manage emotions, when something serious happens it totally makes sense that that will be one the first things to go through the mind. It is its own kind of addiction. There is a therapy, DBT or, Dialectical Behavior Therapy, which focusing on giving you new tools to get through hard times, understand and manage your emotions, to stay present and to deal with relationships. This one of the most effective interventions there is for self-harm. If you are interested in DBT, reach a local therapist in your area and ask if they do DBT or can recommend you to a DBT program. This can help immensely. Self-harm recovery is totally possible, but it is definitely hard work!\n",
      "\n",
      "G :  I self-harm, and I stop for awhile. Then when I see something sad or depressing, I automatically want to self-harm. However, it’s hard to stop. When I’m feeling sad, I stop.\",\"Self-harm can be a painful experience. In addition to stopping for a time and talking to others, it may also be helpful to find a mental health professional to talk to about how to help. It sounds like you have some ideas as to how to\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../data/sample_q_and_a/custom_model\"\n",
    "sequence = data['Question'].iloc[100]\n",
    "max_len = 100\n",
    "print(\"Q : \",data['Question'].iloc[100])\n",
    "print()\n",
    "print(\"A : \",data['Response'].iloc[100])\n",
    "print()\n",
    "print(\"G : \",generate_text(model_path, sequence, max_len)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q :  I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\n",
      "   I’ve never had counseling about any of this. Do I have too many issues to address in counseling?\n",
      "\n",
      "A :  There are never \"too many issues\" to be addressed in therapy.  Most people come in with multiple issues they want to address.  The wonderful thing about therapy, is that often, as one or more significant issues begin to change and improve-   the lead naturally without much effort to improvements in the other areas.  (For example, as you begin to address trauma and betrayal from you past, you may find that the insomnia improves). Your therapist, with you input and direction, can help you to prioritize which problem areas to target first.\n",
      "\n",
      "G :  I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\n",
      "   I’ve never had counseling about any of this. Do I have too many issues to address in counseling?\n",
      "\n",
      "\n",
      "\",\"The best way to begin working on issues that you are having is to look at the ways in which you are most unhappy and start making changes in your behavior.  When you see the situation clearly, you can start to change the way you look at it.  Changing how you behave is often what gets in the way of improving your life.  Change your thinking and thinking patterns and the way that you will interact with others in your life.  Change the way you look\n"
     ]
    }
   ],
   "source": [
    "sequence = data['Question'].iloc[50]\n",
    "max_len = 200\n",
    "print(\"Q : \",data['Question'].iloc[50])\n",
    "print()\n",
    "print(\"A : \",data['Response'].iloc[50])\n",
    "print()\n",
    "print(\"G : \",generate_text(model_path, sequence, max_len)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q :  There are many people willing to lovingly provide me with a home. I have food, clothes, and a university education, but I never feel like I belong. Even when I have a good time with people who are supposed to be close, I feel like I'm just out with friends and I never go home.\n",
      "\n",
      "A :  From the little bit you wrote, my guess is you haven't figured out where and how to lay down your own set of roots.Usually people who have a university level eduction are old enough to work in order to support themselves.Unless you have a medical condition which limits or prevents you from working a full-time job, would you guess that the effort and thought involved in deciding in what professional area and geographic location to look for work, would offer you a way to establish your identity?My suggestion is to pay more attention to your own likes, dislikes, and interests.   To know these areas more deeply would define the type of people with whom you identify, have a common interest and with whom you'd like to socialize.The more you realize who you are, the easier time you'll have to find like-minded others and feel securely at home with them and yourself.Again, if you have a medical disability or condition which prevents employment or easily socializing with other people, then this advice would need to be modified for your specific strengths.\n",
      "\n",
      "G :  There are many people willing to lovingly provide me with a home. I have food, clothes, and a university education, but I never feel like I belong. Even when I have a good time with people who are supposed to be close, I feel like I'm just out with friends and I never go home. Is that what I want?\",\"This may sound like a tough one, but I think it is a great question.  Most people want to be with me, but they don't know how to connect with me.  So, what do you think is the most important issue in your life?  What should I do to feel reconnected?  If you are going to go to see a therapist,  make sure you are taking good care of yourself by attending a therapy retreat together.  There are no exact answers to these questions, but if you are going to see a therapist,  this may help to understand your thoughts and feelings\n"
     ]
    }
   ],
   "source": [
    "sequence = data['Question'].iloc[150]\n",
    "max_len = 200\n",
    "print(\"Q : \",data['Question'].iloc[150])\n",
    "print()\n",
    "print(\"A : \",data['Response'].iloc[150])\n",
    "print()\n",
    "print(\"G : \",generate_text(model_path, sequence, max_len)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q :  what is love\n",
      "\n",
      "G :  what is love and kindness which should be respected if you want to be with your boyfriend.\"\n",
      "1639,\"It was very unsettling at the time. I know I had to leave my mom to travel with me and live with my grandparents. I feel like I need to just lay waste to this.\",\"I'm sorry you were short.  However, it can be helpful to know that at the time of giving up your ability to travel with your parents (or staying in the US) and having friends (people) on your own could have led to depression and anxiety.  It doesn't sound like you have been able to work through this at the time and your depression comes from having this relationship.  As far as your family's reaction to losing your mother, either way, I would ask you to be patient and understand that losing your mother is a loss for you and for your kids.  Your support system seems to be a great support system in your family.  I'm sure if\n"
     ]
    }
   ],
   "source": [
    "#take input from user for sequence \n",
    "sequence = input(\"Enter the question : \")\n",
    "max_len = 200\n",
    "print(\"Q : \",sequence)\n",
    "print()\n",
    "#print only answer not the sequence\n",
    "print(\"G : \",generate_text(model_path, sequence, max_len)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
