{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models import FastText\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import ast\n",
    "import csv\n",
    "import cProfile\n",
    "import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all text files in the knowledge directory\n",
    "def process_text_file(directory):\n",
    "    tagged_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                text = file.read()\n",
    "                tokens = text.split() # Tokenize the text\n",
    "                tagged_data.append(TaggedDocument(words=tokens, tags=[\"text_file\"]))\n",
    "    return tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worker function to process a single CSV file\n",
    "def process_single_csv(file_path):\n",
    "    tagged_data = []\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, quoting=csv.QUOTE_NONE, on_bad_lines='skip')\n",
    "\n",
    "        # Identify all columns of type 'object' (string)\n",
    "        text_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "\n",
    "        if not text_columns:\n",
    "            print(f\"No suitable text columns found in {file_path}. Skipping file.\")\n",
    "            return tagged_data\n",
    "\n",
    "        print(f\"Using columns {text_columns} from {file_path}\")\n",
    "        for index, row in df.iterrows():\n",
    "            tokens = []\n",
    "            for col in text_columns:\n",
    "                column_data = row[col]\n",
    "                # Safely evaluate the string if it looks like a list, otherwise split normally\n",
    "                column_tokens = ast.literal_eval(column_data) if (isinstance(column_data, str) and column_data.startswith('[') and column_data.endswith(']')) else str(column_data).split()\n",
    "                tokens.extend(column_tokens)\n",
    "            tagged_data.append(TaggedDocument(words=tokens, tags=[f\"{os.path.basename(file_path)}_{index}\"]))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "    return tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_files(directory):\n",
    "    files = [os.path.join(directory, filename) for filename in os.listdir(directory) if filename.endswith(\".csv\")]\n",
    "    \n",
    "    # Initialize a pool of worker processes\n",
    "    with Pool(os.cpu_count()) as p:\n",
    "        results = p.map(process_single_csv, files)\n",
    "\n",
    "    # Flatten the list of tagged_data lists into a single list\n",
    "    tagged_data = [item for sublist in results for item in sublist]\n",
    "    return tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using columns ['text'] from ../data/knowledge/preprocess/labelled_disease_or_not_processed.csv\n",
      "Using columns ['subreddit', 'comment'] from ../data/knowledge/preprocess/reddit_types_processed.csv\n",
      "Using columns ['title', 'selftext', 'subreddit'] from ../data/knowledge/preprocess/all_types_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Directory paths\n",
    "directory = \"../data/knowledge/preprocess\"\n",
    "d2v_directory = os.path.join(directory, 'd2v')\n",
    "os.makedirs(d2v_directory, exist_ok=True)\n",
    "# Initialize tagged data list\n",
    "tagged_data = []\n",
    "\n",
    "# Process the all text file that ends with .txt in the directory preprocess under knowledge folder\n",
    "tagged_data.extend(process_text_file(directory))\n",
    "\n",
    "# Process all CSV files in the preprocess directory of knowledge folder\n",
    "tagged_data.extend(process_csv_files(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Doc2Vec model for txt and csv files of knowledge folder using GPU\n",
    "model_d2v_combined = Doc2Vec(vector_size=300, alpha=0.025, min_alpha=0.00025, min_count=2, dm=0, workers=multiprocessing.cpu_count(), epochs=10)\n",
    "model_d2v_combined.build_vocab(tagged_data)\n",
    "model_d2v_combined.train(tagged_data, total_examples=model_d2v_combined.corpus_count, epochs=model_d2v_combined.epochs)\n",
    "\n",
    "# Save the model of knowledge folder\n",
    "model_d2v_combined.save(os.path.join(d2v_directory, 'model_d2v_combined.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_csv_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m tagged_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Process all CSV files in the directory preprocess under sample_qa folder\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m tagged_data\u001b[38;5;241m.\u001b[39mextend(\u001b[43mprocess_csv_files\u001b[49m(directory))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_csv_files' is not defined"
     ]
    }
   ],
   "source": [
    "# Directory paths for sample_q_and_a files\n",
    "directory = \"../data/sample_q_and_a/preprocess\"\n",
    "d2v_directory = os.path.join(directory, 'd2v')\n",
    "os.makedirs(d2v_directory, exist_ok=True)\n",
    "# Initialize tagged data list\n",
    "tagged_data = []\n",
    "# Process all CSV files in the directory preprocess under sample_qa folder\n",
    "tagged_data.extend(process_csv_files(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Doc2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_d2v_qa \u001b[38;5;241m=\u001b[39m \u001b[43mDoc2Vec\u001b[49m(vector_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.025\u001b[39m, min_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00025\u001b[39m, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, workers\u001b[38;5;241m=\u001b[39mmultiprocessing\u001b[38;5;241m.\u001b[39mcpu_count(), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      2\u001b[0m model_d2v_qa\u001b[38;5;241m.\u001b[39mbuild_vocab(tagged_data)\n\u001b[1;32m      3\u001b[0m model_d2v_qa\u001b[38;5;241m.\u001b[39mtrain(tagged_data, total_examples\u001b[38;5;241m=\u001b[39mmodel_d2v_qa\u001b[38;5;241m.\u001b[39mcorpus_count, epochs\u001b[38;5;241m=\u001b[39mmodel_d2v_qa\u001b[38;5;241m.\u001b[39mepochs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Doc2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "model_d2v_qa = Doc2Vec(vector_size=300, alpha=0.025, min_alpha=0.00025, min_count=1, dm=0, workers=multiprocessing.cpu_count(), epochs=100)\n",
    "model_d2v_qa.build_vocab(tagged_data)\n",
    "model_d2v_qa.train(tagged_data, total_examples=model_d2v_qa.corpus_count, epochs=model_d2v_qa.epochs)\n",
    "# Save the model of sample_q_and_a folder\n",
    "model_d2v_qa.save(os.path.join(d2v_directory, 'model_d2v_qa.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_d2v_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# view the model_d2v_qa.model file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel_d2v_combined\u001b[49m\u001b[38;5;241m.\u001b[39mdocvecs[i])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_d2v_combined' is not defined"
     ]
    }
   ],
   "source": [
    "# view the model_d2v_qa.model file\n",
    "for i in range(10):\n",
    "    print(model_d2v_combined.docvecs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_d2v_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel_d2v_combined\u001b[49m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mindex_to_key[i])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_d2v_combined' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(model_d2v_combined.wv.index_to_key[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
